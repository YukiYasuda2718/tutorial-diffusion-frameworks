{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cdc7594",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e95c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import INFO, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(StreamHandler(sys.stdout))\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import copy\n",
    "import dataclasses\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "import typing\n",
    "from functools import partial\n",
    "from typing import Callable, Iterable, List, Literal, Optional, Sequence, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import xarray as xr\n",
    "from einops import rearrange\n",
    "from torch import Tensor, nn\n",
    "from torch.amp import GradScaler\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.style.use(\"tableau-colorblind10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096104be",
   "metadata": {},
   "source": [
    "# Make Lorenz96 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3388083d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dx_i}{dt} = (x_{i+1}-x_{i-2})x_{i-1} - x_i + F\n",
    "$$\n",
    "- $F$ は下の設定で $F=8$ としている．これはカオスレジームとして知られる典型的な設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45d14c",
   "metadata": {},
   "source": [
    "## Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd660a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = pathlib.Path(\".\").resolve()\n",
    "DL_DATA_DIR = str(ROOT_DIR / \"data\" / \"DL_data\" / \"lorenz96\")\n",
    "os.makedirs(DL_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b602b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCHES = 5_000  # 作成するデータセット数\n",
    "N_SPACES = 32  # 空間の格子点数\n",
    "N_TIMES = 5_000  # 時間ステップ数\n",
    "\n",
    "FORCING = 8.0\n",
    "AMP_PERTURBATION = 0.01\n",
    "DT = 0.005\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6382657",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_lorenz96(x0: Tensor, forcing: float, n_steps: int, dt: float) -> Tensor:\n",
    "\n",
    "    assert isinstance(x0, Tensor) and x0.ndim == 2  # batch and space\n",
    "    assert isinstance(forcing, float)\n",
    "    assert isinstance(n_steps, int) and n_steps > 0\n",
    "    assert isinstance(dt, float) and dt > 0.0\n",
    "\n",
    "    current = x0.clone().detach()\n",
    "    states = [current.clone().detach()]\n",
    "\n",
    "    for _ in tqdm(range(n_steps)):\n",
    "        rhs = _lorenz96_rhs(x=current, forcing=forcing)\n",
    "        current = current + dt * rhs\n",
    "        states.append(current.clone().detach())\n",
    "\n",
    "    return torch.stack(states, dim=1).cpu()  # stack along time dim\n",
    "\n",
    "\n",
    "def _lorenz96_rhs(x: Tensor, forcing: float) -> Tensor:\n",
    "\n",
    "    a = x.roll(shifts=-1, dims=1)\n",
    "    b = x.roll(shifts=2, dims=1)\n",
    "    c = x.roll(shifts=1, dims=1)\n",
    "    dxdt = (a - b) * c - x + forcing\n",
    "\n",
    "    return dxdt\n",
    "\n",
    "\n",
    "def set_seeds(seed: int = 42, use_deterministic: bool = True) -> None:\n",
    "    try:\n",
    "        os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed(seed)\n",
    "\n",
    "        if use_deterministic:\n",
    "            torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    except Exception as e:\n",
    "        logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea0a52",
   "metadata": {},
   "source": [
    "## Integrate Lorenz96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c568a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "set_seeds(SEED)\n",
    "x0 = FORCING * torch.ones(size=(N_BATCHES, N_SPACES), dtype=dtype, device=device)\n",
    "x0 += torch.randn_like(x0) * AMP_PERTURBATION\n",
    "\n",
    "states = integrate_lorenz96(x0=x0, forcing=FORCING, n_steps=N_TIMES, dt=DT)\n",
    "\n",
    "if torch.any(torch.isnan(states)):\n",
    "    logger.warning(\"NaNs appear.\")\n",
    "elif torch.any(~torch.isfinite(states)):\n",
    "    logger.warning(\"Infs appear\")\n",
    "else:\n",
    "    logger.info(\"Integration was successfully finished.\")\n",
    "\n",
    "del x0, dtype, device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a4293",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0821922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 14\n",
    "fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=[10, 4])\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    d = states[i].numpy()[::40][\n",
    "        -32:\n",
    "    ]  ## 40 時間ステップごとに抽出し，最後の 32 要素を時間に沿って抽出\n",
    "    ts = np.arange(d.shape[0]) * 20 * DT\n",
    "    xs = np.linspace(0, 2 * math.pi, N_SPACES, endpoint=False)\n",
    "    X, T = np.meshgrid(xs, ts, indexing=\"ij\")\n",
    "    ret = ax.pcolormesh(\n",
    "        X, T, d.transpose(), vmin=-9, vmax=9, cmap=\"coolwarm\", shading=\"nearest\"\n",
    "    )\n",
    "    cbar = fig.colorbar(ret, ax=ax)\n",
    "    ax.set_xlabel(r\"Space, $x$\")\n",
    "    ax.set_ylabel(r\"Time, $t$\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "del d, ts, xs, X, T, ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d22445",
   "metadata": {},
   "source": [
    "## Write out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ae7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = states[:, ::40][:, -32:]\n",
    "## 40 時間ステップごとに抽出し，最後の 32 要素を時間に沿って抽出\n",
    "assert outs.shape == (N_BATCHES, 32, N_SPACES), f\"{outs.shape=}\"\n",
    "\n",
    "ts = np.arange(0.0, outs.shape[1]) * (DT * 40)\n",
    "xs = np.linspace(0, 2 * math.pi, N_SPACES, endpoint=False)\n",
    "\n",
    "da = xr.DataArray(\n",
    "    outs.numpy().astype(np.float32),\n",
    "    dims=[\"batch\", \"time\", \"space\"],\n",
    "    coords={\n",
    "        \"batch\": np.arange(N_BATCHES, dtype=np.int32),\n",
    "        \"time\": ts.astype(np.float32),\n",
    "        \"space\": xs.astype(np.float32),\n",
    "    },\n",
    "    name=\"lorenz96_trajectory\",\n",
    "    attrs={\n",
    "        \"forcing\": FORCING,\n",
    "        \"dt\": DT,\n",
    "        \"seed\": SEED,\n",
    "        \"amp_perturb\": AMP_PERTURBATION,\n",
    "    },\n",
    ")\n",
    "\n",
    "p = f\"{DL_DATA_DIR}/lorenz96_v00.nc\"\n",
    "da.to_netcdf(path=p)\n",
    "\n",
    "del states, outs, ts, xs, da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9714ff",
   "metadata": {},
   "source": [
    "# Tran diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf26f01",
   "metadata": {},
   "source": [
    "- 分散保存型 (Variance-Preserving; VP) の拡散モデルを扱う．\n",
    "- 順過程は下の様に書ける\n",
    "$$\n",
    "\\begin{align}\n",
    "dx_t &= -\\frac{1}{2} \\beta_t x \\; dt + \\sqrt{\\beta_t} \\; dW \\quad (t \\in [0,1]) \\\\\n",
    "\\beta_t &= \\beta_{\\rm start} + t \\beta_{\\rm end}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ac252",
   "metadata": {},
   "source": [
    "## Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "logger.info(f\"{DEVICE=}\")\n",
    "ROOT_DIR = pathlib.Path(\".\").resolve()\n",
    "DL_DATA_DIR = str(ROOT_DIR / \"data\" / \"DL_data\" / \"lorenz96\")\n",
    "DL_DATA_FILE = str(ROOT_DIR / \"data\" / \"DL_data\" / \"lorenz96\" / \"lorenz96_v00.nc\")\n",
    "DL_RESULT_DIR = str(ROOT_DIR / \"data\" / \"DL_model\" / \"lorenz96_v00\")\n",
    "os.makedirs(DL_RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f806afab",
   "metadata": {},
   "source": [
    "## Make config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass()\n",
    "class DDPMConfig:\n",
    "    start_beta: float\n",
    "    end_beta: float\n",
    "    n_timesteps: int\n",
    "    n_channels: int\n",
    "    n_spaces: int\n",
    "\n",
    "\n",
    "@dataclasses.dataclass()\n",
    "class ExperimentLorenz96Config:\n",
    "    batch_size: int\n",
    "    loss_name: str\n",
    "    learning_rate: float\n",
    "    #\n",
    "    n_features: int\n",
    "    list_channel: list[int]\n",
    "    #\n",
    "    total_epochs: int\n",
    "    save_interval: int\n",
    "    use_auto_mix_precision: bool\n",
    "    ddpm: DDPMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69987a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExperimentLorenz96Config(\n",
    "    # Training settings\n",
    "    batch_size=100,\n",
    "    loss_name=\"L2\",\n",
    "    learning_rate=1e-3,\n",
    "    total_epochs=40,\n",
    "    save_interval=4,\n",
    "    use_auto_mix_precision=False,\n",
    "    # For U-Net\n",
    "    n_features=32,\n",
    "    list_channel=[1, 2, 4],\n",
    "    # For DDPM\n",
    "    ddpm=DDPMConfig(\n",
    "        start_beta=1e1,  # start_beta == end_beta の設定により，beta を定数にする\n",
    "        end_beta=1e1,\n",
    "        n_timesteps=1_000,\n",
    "        n_channels=32,  # データの時間ステップ数をチャネル数として指定\n",
    "        n_spaces=32,  # 空間格子点数．dont change n_channels and n_spaces\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01480e45",
   "metadata": {},
   "source": [
    "## Make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLorenz96(Dataset):\n",
    "    def __init__(self, path_to_dataarray: str):\n",
    "\n",
    "        self.data = xr.load_dataarray(path_to_dataarray)\n",
    "        assert self.data.dims == (\"batch\", \"time\", \"space\")\n",
    "\n",
    "        self.n_batch, self.n_times, self.n_spaces = self.data.shape\n",
    "        self.mean = self.data.mean().item()\n",
    "        self.std = self.data.std().item()\n",
    "\n",
    "        self.dtype = torch.float32\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]  # batch dimension\n",
    "\n",
    "    def standardize(self, data):\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "    def standardize_inversely(self, data):\n",
    "        return data * self.std + self.mean\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict[str, torch.Tensor]:\n",
    "        data = self.data[idx].values  # time x space\n",
    "        standardized = self.standardize(data)\n",
    "        ret = torch.tensor(standardized, dtype=self.dtype)\n",
    "        assert ret.shape == (self.n_times, self.n_spaces)\n",
    "        return {\"y0\": ret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=DatasetLorenz96(DL_DATA_FILE),\n",
    "    batch_size=config.batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e348cde",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c98b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(dataloader))[\"y0\"]\n",
    "assert data.shape == (\n",
    "    config.batch_size,\n",
    "    config.ddpm.n_channels,\n",
    "    config.ddpm.n_spaces,\n",
    ")  # batch, time (=channel), space dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b687137",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 14\n",
    "fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=[10, 4])\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    d = dataloader.dataset.standardize_inversely(data[i].numpy())\n",
    "    ts = np.arange(d.shape[0]) * 0.2  # dt = 0.2\n",
    "    xs = np.linspace(0, 2 * math.pi, 32, endpoint=False)\n",
    "    X, T = np.meshgrid(xs, ts, indexing=\"ij\")\n",
    "    ret = ax.pcolormesh(\n",
    "        X, T, d.transpose(), vmin=-9, vmax=9, cmap=\"coolwarm\", shading=\"nearest\"\n",
    "    )\n",
    "    cbar = fig.colorbar(ret, ax=ax)\n",
    "    ax.set_xlabel(r\"Space, $x$\")\n",
    "    ax.set_ylabel(r\"Time, $t$\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "del d, ts, xs, X, T, ret, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b67a9",
   "metadata": {},
   "source": [
    "## Define diffusion model framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: DDPMConfig,\n",
    "        neural_net: nn.Module,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dtype = torch.float32\n",
    "        self.device = device\n",
    "        self.c = copy.deepcopy(config)\n",
    "        self.net = neural_net\n",
    "        self._set_noise_schedule()\n",
    "\n",
    "    def _set_noise_schedule(self):\n",
    "        to_torch = partial(torch.tensor, dtype=self.dtype, device=self.device)\n",
    "\n",
    "        betas = _make_beta_schedule(\n",
    "            schedule=\"linear\",\n",
    "            start=self.c.start_beta,\n",
    "            end=self.c.end_beta,\n",
    "            n_timesteps=self.c.n_timesteps,\n",
    "        )\n",
    "        times = np.linspace(\n",
    "            0.0, 1.0, num=len(betas) + 1, endpoint=True, dtype=np.float64\n",
    "        )\n",
    "        times = times[1:]  # skip the initial value\n",
    "        assert len(times) == len(betas) == self.c.n_timesteps\n",
    "\n",
    "        self.dt = 1.0 / float(self.c.n_timesteps)\n",
    "        self.sqrt_dt = math.sqrt(self.dt)\n",
    "\n",
    "        # variance-preserving SDE\n",
    "        frictions = 0.5 * betas\n",
    "        sigmas = np.sqrt(betas)\n",
    "\n",
    "        decays, vars = _precompute_ou(mu=frictions, sigma=sigmas, dt=self.dt)\n",
    "        stds = np.sqrt(vars)\n",
    "        # the OU solution is expressed as x_t = decay * x_0 + std * epsilon (epsilon ~ N(0,1))\n",
    "\n",
    "        # the number of elements in each param is equal to self.c.n_timesteps\n",
    "        self.register_buffer(\"frictions\", to_torch(frictions))\n",
    "        self.register_buffer(\"sigmas\", to_torch(sigmas))\n",
    "        self.register_buffer(\"times\", to_torch(times))\n",
    "\n",
    "        # Register params except for the initial values because std is initially zero\n",
    "        # Later, std is used as denominator to convert noise into the score function.\n",
    "        self.register_buffer(\"decays\", to_torch(decays[1:]))\n",
    "        self.register_buffer(\"stds\", to_torch(stds[1:]))\n",
    "\n",
    "        assert (\n",
    "            self.frictions.shape\n",
    "            == self.sigmas.shape\n",
    "            == self.times.shape\n",
    "            == self.decays.shape\n",
    "            == self.stds.shape\n",
    "            == (self.c.n_timesteps,)\n",
    "        )\n",
    "        assert torch.all(self.sigmas > 0.0) and torch.all(self.stds > 0.0)\n",
    "\n",
    "    def _extract_params(\n",
    "        self, params: torch.Tensor, t_indices: torch.Tensor, for_broadcast: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        def select(array):\n",
    "            return torch.index_select(array, dim=0, index=t_indices)\n",
    "            # Select diffusion times along batch dim\n",
    "\n",
    "        (n_batches,) = t_indices.shape\n",
    "\n",
    "        selected = select(params)\n",
    "        assert selected.shape == (n_batches,)\n",
    "\n",
    "        # add channel and space dims\n",
    "        if for_broadcast:\n",
    "            return selected.requires_grad_(False)[:, None, None]\n",
    "        else:\n",
    "            return selected.requires_grad_(False)\n",
    "\n",
    "    def _forward_sample_y(\n",
    "        self, y0: torch.Tensor, t_index: torch.Tensor, noise: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        #\n",
    "        a = self._extract_params(self.decays, t_index)\n",
    "        b = self._extract_params(self.stds, t_index)\n",
    "        return a * y0 + b * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _backward_sample_y(\n",
    "        self,\n",
    "        yt: torch.Tensor,\n",
    "        t_index: torch.Tensor,\n",
    "        y_cond: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        friction = self._extract_params(self.frictions, t_index)\n",
    "        sigma = self._extract_params(self.sigmas, t_index)\n",
    "        std = self._extract_params(self.stds, t_index)\n",
    "        t = self._extract_params(self.times, t_index, for_broadcast=False)\n",
    "        t = t[:, None]  # add channel dim\n",
    "\n",
    "        est_noise = self.net(yt=yt, y_cond=y_cond, t=t, t_index=t_index)\n",
    "        score = -est_noise / std\n",
    "\n",
    "        mean = yt + self.dt * (friction * yt + (sigma**2) * score)\n",
    "        dW = self.sqrt_dt * torch.randn_like(yt)\n",
    "\n",
    "        n_batches = yt.shape[0]\n",
    "        mask = (1 - (t_index == 0).float()).reshape(n_batches, *((1,) * (yt.ndim - 1)))\n",
    "        mask = mask.to(dtype=self.dtype, device=self.device)\n",
    "        # no noise at t_index == 0\n",
    "\n",
    "        return mean + mask * sigma * dW\n",
    "\n",
    "    # public methods\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def backward_sample_y(\n",
    "        self,\n",
    "        n_batches: int,\n",
    "        y_cond: Optional[torch.Tensor] = None,\n",
    "        n_return_steps: Optional[int] = None,\n",
    "        tqdm_disable: bool = False,\n",
    "    ) -> dict[int, torch.Tensor]:\n",
    "        assert not self.net.training\n",
    "\n",
    "        size = (n_batches, self.c.n_channels, self.c.n_spaces)\n",
    "        yt = torch.randn(size=size, device=self.device)\n",
    "        yt = self.stds[-1] * yt\n",
    "\n",
    "        if n_return_steps is not None:\n",
    "            interval = self.c.n_timesteps // n_return_steps\n",
    "\n",
    "        intermidiates: dict[int, torch.Tensor] = {}\n",
    "\n",
    "        for i in tqdm(\n",
    "            reversed(range(0, self.c.n_timesteps)),\n",
    "            total=self.c.n_timesteps,\n",
    "            disable=tqdm_disable,\n",
    "        ):\n",
    "            if interval is not None and (i + 1) % interval == 0:\n",
    "                intermidiates[i + 1] = yt.detach().clone().cpu()\n",
    "\n",
    "            index = torch.full((n_batches,), i, device=self.device, dtype=torch.long)\n",
    "            yt = self._backward_sample_y(yt=yt, y_cond=y_cond, t_index=index)\n",
    "\n",
    "        intermidiates[0] = yt.detach().clone().cpu()\n",
    "\n",
    "        return intermidiates\n",
    "\n",
    "    def forward(\n",
    "        self, y0: torch.Tensor, y_cond: Optional[torch.Tensor] = None, **kwargs\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        assert y0.ndim == 3  # batch, channel, space\n",
    "        assert y0.shape[1] == self.c.n_channels\n",
    "        assert y0.shape[2] == self.c.n_spaces\n",
    "\n",
    "        b = y0.shape[0]\n",
    "        t_index = torch.randint(0, self.c.n_timesteps, (b,), device=self.device).long()\n",
    "\n",
    "        noise = torch.randn_like(y0)\n",
    "\n",
    "        yt = self._forward_sample_y(y0=y0, t_index=t_index, noise=noise)\n",
    "        t = self._extract_params(self.times, t_index, for_broadcast=False)\n",
    "        t = t[:, None]  # add channel dim\n",
    "        noise_hat = self.net(yt=yt, y_cond=y_cond, t=t, t_index=t_index)\n",
    "\n",
    "        return noise, noise_hat\n",
    "\n",
    "\n",
    "def _make_beta_schedule(\n",
    "    schedule: str,\n",
    "    start: float,\n",
    "    end: float,\n",
    "    n_timesteps: int,\n",
    ") -> np.ndarray:\n",
    "    if schedule == \"linear\":\n",
    "        betas = np.linspace(start, end, n_timesteps, dtype=np.float64, endpoint=True)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Not supported: {schedule=}\")\n",
    "    return betas\n",
    "\n",
    "\n",
    "def _precompute_ou(\n",
    "    mu: np.ndarray,\n",
    "    sigma: np.ndarray,\n",
    "    dt: float | np.ndarray,\n",
    "    init_variance: float = 0.0,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Method to compute the mean and variance for OU process.\n",
    "    OU process: dx = -mu x dt + sigma dW\n",
    "    \"\"\"\n",
    "    mu = np.array(mu, dtype=np.float64)\n",
    "    assert np.all(mu >= 0.0)\n",
    "\n",
    "    sigma = np.array(sigma, dtype=np.float64)\n",
    "    assert np.all(sigma >= 0.0)\n",
    "\n",
    "    if isinstance(dt, float):\n",
    "        dt = np.full_like(mu, dt, dtype=np.float64)\n",
    "    else:\n",
    "        dt = np.array(dt, dtype=np.float64)\n",
    "    assert mu.shape == sigma.shape == dt.shape\n",
    "    assert init_variance >= 0.0\n",
    "\n",
    "    N = mu.size\n",
    "    m = np.empty(N + 1, dtype=np.float64)  # mean\n",
    "    v = np.empty(N + 1, dtype=np.float64)  # variance\n",
    "    m[0] = 1.0\n",
    "    v[0] = init_variance\n",
    "\n",
    "    for n in range(N):\n",
    "        decay = np.exp(-mu[n] * dt[n])\n",
    "        m[n + 1] = decay * m[n]\n",
    "        if mu[n] == 0.0:\n",
    "            q = sigma[n] ** 2 * dt[n]\n",
    "        else:\n",
    "            q = sigma[n] ** 2 * (1.0 - decay**2) / (2.0 * mu[n])\n",
    "        v[n + 1] = decay**2 * v[n] + q\n",
    "\n",
    "    return np.array(m), np.array(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e32c6",
   "metadata": {},
   "source": [
    "## Define unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ee39c",
   "metadata": {},
   "source": [
    "### Define blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5589a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Downsample1D(\n",
    "    dim: int, kernel_size: int = 4, padding_mode: str = \"zeros\"\n",
    ") -> nn.Module:\n",
    "    return nn.Conv1d(\n",
    "        dim,\n",
    "        dim,\n",
    "        kernel_size=(kernel_size,),\n",
    "        stride=(kernel_size // 2,),\n",
    "        padding=(1,),\n",
    "        padding_mode=padding_mode,\n",
    "    )\n",
    "\n",
    "\n",
    "def Upsample1D(dim: int, kernel_size: int = 4) -> nn.Module:\n",
    "    return nn.ConvTranspose1d(\n",
    "        dim, dim, kernel_size=(kernel_size,), stride=(kernel_size // 2,), padding=(1,)\n",
    "    )\n",
    "\n",
    "\n",
    "def PeriodicDownsample1D(dim: int, kernel_size: int) -> nn.Module:\n",
    "    assert kernel_size % 2 == 1, \"kernel_size should be odd.\"\n",
    "    return nn.Conv1d(\n",
    "        dim,\n",
    "        dim,\n",
    "        kernel_size=(kernel_size,),\n",
    "        stride=(2,),\n",
    "        padding=((kernel_size - 1) // 2,),\n",
    "        padding_mode=\"circular\",\n",
    "    )\n",
    "\n",
    "\n",
    "class PeriodicUpsampleConv1d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_ch: int,\n",
    "        kernel_size: int,\n",
    "        out_ch: Optional[int] = None,\n",
    "        scale: int = 2,\n",
    "    ):\n",
    "        assert kernel_size % 2 == 1, \"kernel_size should be odd.\"\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "        self.pad = (kernel_size - 1) // 2\n",
    "\n",
    "        out_ch = in_ch if out_ch is None else out_ch\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=scale, mode=\"nearest-exact\")\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_ch,\n",
    "            out_ch,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=self.pad,\n",
    "            padding_mode=\"circular\",\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98775c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm1D(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.scale = dim**0.5\n",
    "        self.gamma = nn.Parameter(torch.ones(dim, 1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Normalize along the channel dimension\n",
    "        return F.normalize(x, dim=1) * self.scale * self.gamma\n",
    "\n",
    "\n",
    "class FiLMBlock1D(nn.Module):\n",
    "\n",
    "    def __init__(self, dim: int, dim_out: int, padding_mode: str):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv1d(\n",
    "            dim, dim_out, kernel_size=3, padding=1, padding_mode=padding_mode\n",
    "        )\n",
    "        self.norm = RMSNorm1D(dim_out)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        scale_shift: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if scale_shift is not None:\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        return self.act(x)\n",
    "\n",
    "\n",
    "class ResnetBlock1D(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        dim_out: int,\n",
    "        padding_mode: str,\n",
    "        *,\n",
    "        time_emb_dim: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.mlp = (\n",
    "            nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out * 2))\n",
    "            if time_emb_dim is not None\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.block1 = FiLMBlock1D(dim, dim_out, padding_mode=padding_mode)\n",
    "        self.block2 = FiLMBlock1D(dim_out, dim_out, padding_mode=padding_mode)\n",
    "        self.res_conv = (\n",
    "            nn.Conv1d(dim, dim_out, kernel_size=1) if dim != dim_out else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, time_emb: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        scale_shift = None\n",
    "        if self.mlp is not None:\n",
    "            assert time_emb is not None\n",
    "            emb: torch.Tensor = self.mlp(time_emb)\n",
    "            scale_shift = rearrange(emb, \"b c -> b c 1\").chunk(2, dim=1)\n",
    "\n",
    "        h = self.block1(x, scale_shift=scale_shift)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52021fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, dim: int, time_base: float):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.time_base = time_base\n",
    "        logger.info(f\"SinusoidalTimeEmbedding: {self.time_base=}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.log(torch.tensor(self.time_base, device=device)) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37613f7b",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet1D(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        padding_mode: Literal[\"zeros\", \"circular\"] = \"zeros\",\n",
    "        dim_mults: Sequence[int] = (1, 2, 4, 8),\n",
    "        init_dim: Optional[int] = None,\n",
    "        init_kernel_size: int = 5,\n",
    "        time_base: float = 1000.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        init_dim = dim if init_dim is None else init_dim\n",
    "        assert isinstance(init_dim, int)\n",
    "        assert init_kernel_size % 2 == 1, \"init kernel size must be odd\"\n",
    "\n",
    "        init_padding = init_kernel_size // 2\n",
    "        self.init_conv = nn.Conv1d(\n",
    "            in_channels,\n",
    "            init_dim,\n",
    "            kernel_size=init_kernel_size,\n",
    "            padding=init_padding,\n",
    "            padding_mode=padding_mode,\n",
    "        )\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        time_dim = dim * 4\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalTimeEmbedding(dim, time_base),\n",
    "            nn.Linear(dim, time_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "        )\n",
    "\n",
    "        self.downs: Iterable[nn.Module] = nn.ModuleList([])\n",
    "        self.ups: Iterable[nn.Module] = nn.ModuleList([])\n",
    "\n",
    "        num_resolutions = len(in_out)\n",
    "        block_class = ResnetBlock1D\n",
    "        block_class_cond = partial(\n",
    "            block_class, time_emb_dim=time_dim, padding_mode=padding_mode\n",
    "        )\n",
    "\n",
    "        Downsample: Callable[[int], nn.Module] = Downsample1D\n",
    "        if padding_mode == \"circular\":\n",
    "            logger.info(\"PeriodicDownsample1D is used.\")\n",
    "            Downsample = partial(PeriodicDownsample1D, kernel_size=5)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "            self.downs.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_class_cond(dim_in, dim_out),\n",
    "                        block_class_cond(dim_out, dim_out),\n",
    "                        (Downsample(dim_out) if not is_last else nn.Identity()),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_class_cond(mid_dim, mid_dim)\n",
    "        self.mid_block2 = block_class_cond(mid_dim, mid_dim)\n",
    "\n",
    "        Upsample: nn.Module | Callable[[int], nn.Module] = Upsample1D\n",
    "        if padding_mode == \"circular\":\n",
    "            logger.info(\"PeriodicUpsampleConv1d is used.\")\n",
    "            Upsample = partial(PeriodicUpsampleConv1d, kernel_size=5)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "            self.ups.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_class_cond(dim_out * 2, dim_in),\n",
    "                        block_class_cond(dim_in, dim_in),\n",
    "                        Upsample(dim_in) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.final_conv = nn.Sequential(\n",
    "            block_class(dim * 2, dim, padding_mode=padding_mode),\n",
    "            nn.Conv1d(dim, out_channels, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        yt: torch.Tensor,\n",
    "        y_cond: torch.Tensor,  # not used\n",
    "        t_index: torch.Tensor,\n",
    "        **kwargs,\n",
    "    ) -> torch.Tensor:\n",
    "        # x shape = b c h\n",
    "        # time shape = b\n",
    "\n",
    "        yt = self.init_conv(yt)\n",
    "        r = yt.clone()\n",
    "        t_index = self.time_mlp(t_index)\n",
    "\n",
    "        h: List[torch.Tensor] = []\n",
    "\n",
    "        for downs in self.downs:\n",
    "            assert isinstance(downs, nn.ModuleList)\n",
    "            block1, block2, downsample = downs\n",
    "            yt = block1(yt, t_index)\n",
    "            yt = block2(yt, t_index)\n",
    "            h.append(yt)\n",
    "            yt = downsample(yt)\n",
    "\n",
    "        yt = self.mid_block1(yt, t_index)\n",
    "        yt = self.mid_block2(yt, t_index)\n",
    "\n",
    "        for ups in self.ups:\n",
    "            assert isinstance(ups, nn.ModuleList)\n",
    "            block1, block2, upsample = ups\n",
    "            yt = torch.cat((yt, h.pop()), dim=1)\n",
    "            yt = block1(yt, t_index)\n",
    "            yt = block2(yt, t_index)\n",
    "            yt = upsample(yt)\n",
    "\n",
    "        yt = torch.cat((yt, r), dim=1)\n",
    "\n",
    "        return self.final_conv(yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6cd89",
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a6c28",
   "metadata": {},
   "source": [
    "### Define loss funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd43121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(torch.nn.Module, metaclass=abc.ABCMeta):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def forward(\n",
    "        self, predicts: torch.Tensor, targets: torch.Tensor, masks: torch.Tensor\n",
    "    ):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "def make_loss(loss_name: str) -> CustomLoss:\n",
    "    if loss_name == \"L2\":\n",
    "        logger.info(\"L2 loss is created.\")\n",
    "        return L2Loss()\n",
    "    elif loss_name == \"L1\":\n",
    "        logger.info(\"L1 loss is created.\")\n",
    "        return L1Loss()\n",
    "    else:\n",
    "        raise ValueError(f\"{loss_name} is not supported.\")\n",
    "\n",
    "\n",
    "class L2Loss(CustomLoss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(\n",
    "        self, predicts: torch.Tensor, targets: torch.Tensor, masks: torch.Tensor\n",
    "    ):\n",
    "        return self.loss(predicts, targets)\n",
    "\n",
    "\n",
    "class L1Loss(CustomLoss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.loss = nn.L1Loss()\n",
    "\n",
    "    def forward(\n",
    "        self, predicts: torch.Tensor, targets: torch.Tensor, masks: torch.Tensor\n",
    "    ):\n",
    "        return self.loss(predicts, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79056ec5",
   "metadata": {},
   "source": [
    "### Construct diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e2b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "\n",
    "unet = Unet1D(\n",
    "    dim=config.n_features,\n",
    "    in_channels=32,  # num of times\n",
    "    out_channels=32,  # dont change in_channels and out_channels\n",
    "    padding_mode=\"circular\",\n",
    "    dim_mults=config.list_channel,\n",
    ").to(DEVICE)\n",
    "\n",
    "ddpm = DDPM(config=config.ddpm, neural_net=unet, device=DEVICE)\n",
    "\n",
    "loss_fn = make_loss(loss_name=config.loss_name)\n",
    "optimizer = torch.optim.AdamW(ddpm.parameters(), lr=config.learning_rate)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3365a964",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f4e9c",
   "metadata": {},
   "source": [
    "### Define training method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0.0\n",
    "        self.avg = 0.0\n",
    "        self.sum = 0.0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def optimize_ddpm(\n",
    "    *,\n",
    "    dataloader: DataLoader,\n",
    "    ddpm: DDPM,\n",
    "    loss_fn: CustomLoss,\n",
    "    optimizer: Optimizer,\n",
    "    epoch: int,\n",
    "    mode: typing.Literal[\"train\", \"valid\", \"test\"],\n",
    "    scaler: GradScaler,\n",
    "    use_amp: bool,\n",
    ") -> float:\n",
    "    #\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    d = next(ddpm.net.parameters()).device\n",
    "    device = str(d)\n",
    "\n",
    "    if mode == \"train\":\n",
    "        ddpm.net.train()\n",
    "    elif mode in [\"valid\", \"test\"]:\n",
    "        ddpm.net.eval()\n",
    "    else:\n",
    "        raise ValueError(f\"{mode} is not supported.\")\n",
    "\n",
    "    random.seed(epoch)\n",
    "    np.random.seed(epoch)\n",
    "\n",
    "    device_type = \"cuda\" if \"cuda\" in device else \"cpu\"\n",
    "\n",
    "    for batch in dataloader:\n",
    "\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].to(device, non_blocking=True)\n",
    "\n",
    "        if mode == \"train\":\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.autocast(\n",
    "                device_type=device_type, dtype=torch.float16, enabled=use_amp\n",
    "            ):\n",
    "                noise, noise_hat = ddpm(**batch)\n",
    "                loss = loss_fn(predicts=noise_hat, targets=noise, masks=None)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad(), torch.autocast(\n",
    "                device_type=device_type, dtype=torch.float16, enabled=use_amp\n",
    "            ):\n",
    "                noise, noise_hat = ddpm(**batch)\n",
    "                loss = loss_fn(predicts=noise_hat, targets=noise, masks=None)\n",
    "\n",
    "        loss_meter.update(loss.item(), n=noise.shape[0])\n",
    "\n",
    "    return loss_meter.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca4e34",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42069ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "all_scores: list[dict] = []\n",
    "set_seeds(42)\n",
    "\n",
    "with tqdm(total=config.total_epochs, desc=\"Training Progress\", unit=\"step\") as pbar:\n",
    "    for _epoch in range(config.total_epochs):\n",
    "        epoch = _epoch + 1  # 0 から始まるため，1 を足す\n",
    "\n",
    "        loss = optimize_ddpm(\n",
    "            dataloader=dataloader,\n",
    "            ddpm=ddpm,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            epoch=epoch,\n",
    "            mode=\"train\",\n",
    "            scaler=scaler,\n",
    "            use_amp=config.use_auto_mix_precision,\n",
    "        )\n",
    "        all_scores.append({\"epoch\": epoch, \"loss\": loss})\n",
    "\n",
    "        if epoch % config.save_interval == 0:\n",
    "            p = f\"{DL_RESULT_DIR}/model_weight_{epoch:06}.pth\"\n",
    "            torch.save(ddpm.net.state_dict(), p)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == config.total_epochs:\n",
    "            p = f\"{DL_RESULT_DIR}/loss_history.csv\"\n",
    "            pd.DataFrame(all_scores).to_csv(p, index=False)\n",
    "\n",
    "        pbar.set_postfix({\"loss\": loss})\n",
    "        pbar.update(1)\n",
    "\n",
    "end_time = time.time()\n",
    "logger.info(f\"Finished. Total elapsed time = {(end_time - start_time) / 60.} min\")\n",
    "del epoch, _epoch, loss, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f42f95",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcc979",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = config.total_epochs\n",
    "p = f\"{DL_RESULT_DIR}/model_weight_{epoch:06}.pth\"\n",
    "unet.load_state_dict(torch.load(p, map_location=DEVICE, weights_only=False))\n",
    "_ = unet.eval()\n",
    "del epoch, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1ea49",
   "metadata": {},
   "source": [
    "## Run sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "dict_samples = ddpm.backward_sample_y(n_batches=50, n_return_steps=1000)\n",
    "# n_return_steps == 1000, つまり，1000 ステップを 1000 等分するように，中間状態を返す\n",
    "# この場合，1 ステップごとに返ってくる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e94e84",
   "metadata": {},
   "source": [
    "## Plot generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aee61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_samples = dict_samples[0]  # at t == 0\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=[10, 4])\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    d = last_samples[i].cpu().numpy()\n",
    "    d = dataloader.dataset.standardize_inversely(d)\n",
    "    ts = np.arange(d.shape[0]) * 0.2  # dt = 0.2\n",
    "    xs = np.linspace(0, 2 * math.pi, 32, endpoint=False)\n",
    "    X, T = np.meshgrid(xs, ts, indexing=\"ij\")\n",
    "    ret = ax.pcolormesh(\n",
    "        X, T, d.transpose(), vmin=-9, vmax=9, cmap=\"coolwarm\", shading=\"nearest\"\n",
    "    )\n",
    "    cbar = fig.colorbar(ret, ax=ax)\n",
    "    ax.set_xlabel(r\"Space, $x$\")\n",
    "    ax.set_ylabel(r\"Time, $t$\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "del d, ts, xs, X, T, ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de8a162",
   "metadata": {},
   "source": [
    "## Run spectral analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20910122",
   "metadata": {},
   "source": [
    "- ノイズによりエネルギーが注入され，スペクトルが平坦に近づく\n",
    "- 逆過程では，その平坦なスペクトルから初めて，段々と時空間構造を復元する\n",
    "- ノイズは，全ての格子点で独立に作用し，データの時空間構造を一切加味することなく破壊する\n",
    "- そのため，エネルギーが平均より大きいスケールでエネルギーの注入が起こり，逆にエネルギーが小さいスケールでエネルギーの減衰が起こる\n",
    "- この注入と減衰は，スケールの大きさではなくて，エネルギーの大きさで決定される\n",
    "- 例えば，空間スペクトルを見ると，$k$ の小さな領域と大きな領域でエネルギーが注入されている"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
