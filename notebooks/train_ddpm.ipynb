{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77721671",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dce5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import INFO, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(StreamHandler(sys.stdout))\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d9ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "from src.utils.random_seed_helper import set_seeds, seed_worker, get_torch_generator\n",
    "from src.frameworks.ddpm import DDPM, DDPMConfig\n",
    "from src.datasets.dataset_lorenz96 import DatasetLorenz96\n",
    "from src.configs.lorenz96_config import ExperimentLorenz96Config\n",
    "from src.neural_networks.unet_1d import Unet1D\n",
    "from src.training.loss_maker import make_loss\n",
    "from src.training.optim_helper import optimize_ddpm\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.style.use(\"tableau-colorblind10\")\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = r\":4096:8\"  # to make calculations deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4240d6a",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "ROOT_DIR = pathlib.Path(os.environ[\"PYTHONPATH\"].split(\":\")[0]).resolve()\n",
    "DL_DATA_FILE = str(ROOT_DIR / \"data\" / \"DL_data\" / \"lorenz96\" / \"lorenz96_v00.nc\")\n",
    "DL_RESULT_DIR = str(ROOT_DIR / \"data\" / \"DL_model\" / \"lonrenz96_v00\")\n",
    "os.makedirs(DL_RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c47050",
   "metadata": {},
   "source": [
    "# Make config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExperimentLorenz96Config(\n",
    "    batch_size=100,\n",
    "    loss_name=\"L2\",\n",
    "    learning_rate=1e-3,\n",
    "    #\n",
    "    n_features=32,\n",
    "    list_channel=[1, 2, 4],\n",
    "    #\n",
    "    total_epochs=40,\n",
    "    save_interval=4,\n",
    "    use_auto_mix_precision=False,\n",
    "    #\n",
    "    ddpm=DDPMConfig(\n",
    "        start_beta=1e-3,\n",
    "        end_beta=3e1,\n",
    "        n_timesteps=1_000,\n",
    "        n_channels=32,\n",
    "        n_spaces=32,  # dont change n_channels and n_spaces\n",
    "    ),\n",
    ")\n",
    "config.save(f\"{DL_RESULT_DIR}/config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bb69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can load your saved config.\n",
    "# config = ExperimentLorenz96Config.load(f\"{DL_RESULT_DIR}/config.yml\")\n",
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9327275",
   "metadata": {},
   "source": [
    "# Make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=DatasetLorenz96(DL_DATA_FILE),\n",
    "    batch_size=config.batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=get_torch_generator(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(dataloader))[\"y0\"]\n",
    "assert data.shape == (\n",
    "    config.batch_size,\n",
    "    config.ddpm.n_channels,\n",
    "    config.ddpm.n_spaces,\n",
    ")  # batch, time (=channel), space dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715d2ab",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c09114",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 14\n",
    "fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=[10, 4])\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    d = dataloader.dataset.standardize_inversely(data[i].numpy())\n",
    "    ts = np.arange(d.shape[0]) * 0.2  # dt = 0.2\n",
    "    xs = np.linspace(0, 2 * math.pi, 32, endpoint=False)\n",
    "    X, T = np.meshgrid(xs, ts, indexing=\"ij\")\n",
    "    ret = ax.pcolormesh(\n",
    "        X, T, d.transpose(), vmin=-9, vmax=9, cmap=\"coolwarm\", shading=\"nearest\"\n",
    "    )\n",
    "    cbar = fig.colorbar(ret, ax=ax)\n",
    "    ax.set_xlabel(r\"Space, $x$\")\n",
    "    ax.set_ylabel(r\"Time, $t$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc531bcb",
   "metadata": {},
   "source": [
    "# Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56881d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "\n",
    "unet = Unet1D(\n",
    "    dim=config.n_features,\n",
    "    in_channels=32,  # num of times\n",
    "    out_channels=32,\n",
    "    padding_mode=\"circular\",\n",
    "    dim_mults=config.list_channel,\n",
    ").to(DEVICE)\n",
    "\n",
    "ddpm = DDPM(config=config.ddpm, neural_net=unet, device=DEVICE)\n",
    "\n",
    "loss_fn = make_loss(loss_name=config.loss_name)\n",
    "optimizer = torch.optim.AdamW(ddpm.parameters(), lr=config.learning_rate)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729b4b1",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cdfba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "all_scores: list[dict] = []\n",
    "set_seeds(42)\n",
    "\n",
    "with tqdm(total=config.total_epochs, desc=\"Training Progress\", unit=\"step\") as pbar:\n",
    "    for _epoch in range(config.total_epochs):\n",
    "        epoch = _epoch + 1\n",
    "\n",
    "        loss = optimize_ddpm(\n",
    "            dataloader=dataloader,\n",
    "            ddpm=ddpm,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            epoch=epoch,\n",
    "            mode=\"train\",\n",
    "            scaler=scaler,\n",
    "            use_amp=config.use_auto_mix_precision,\n",
    "        )\n",
    "        all_scores.append({\"epoch\": epoch, \"loss\": loss})\n",
    "\n",
    "        if epoch % config.save_interval == 0:\n",
    "            p = f\"{DL_RESULT_DIR}/model_weight_{epoch:06}.pth\"\n",
    "            torch.save(ddpm.net.state_dict(), p)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == config.total_epochs:\n",
    "            p = f\"{DL_RESULT_DIR}/loss_history.csv\"\n",
    "            pd.DataFrame(all_scores).to_csv(p, index=False)\n",
    "\n",
    "        pbar.set_postfix({\"loss\": loss})\n",
    "        pbar.update(1)\n",
    "\n",
    "end_time = time.time()\n",
    "logger.info(f\"Finished. Total elapsed time = {(end_time - start_time) / 60.} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c63a703",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170eb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = config.total_epochs\n",
    "p = f\"{DL_RESULT_DIR}/model_weight_{epoch:06}.pth\"\n",
    "unet.load_state_dict(torch.load(p, map_location=DEVICE, weights_only=False))\n",
    "_ = unet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de4595",
   "metadata": {},
   "source": [
    "## Run sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dbbcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "dict_samples = ddpm.backward_sample_y(n_batches=10, n_return_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff3b91",
   "metadata": {},
   "source": [
    "## Plot generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_samples = dict_samples[0]\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "fig, axes = plt.subplots(1, 3, sharex=True, sharey=True, figsize=[10, 4])\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    d = last_samples[i].cpu().numpy()\n",
    "    d = dataloader.dataset.standardize_inversely(d)\n",
    "    ts = np.arange(d.shape[0]) * 0.2  # dt = 0.2\n",
    "    xs = np.linspace(0, 2 * math.pi, 32, endpoint=False)\n",
    "    X, T = np.meshgrid(xs, ts, indexing=\"ij\")\n",
    "    ret = ax.pcolormesh(\n",
    "        X, T, d.transpose(), vmin=-9, vmax=9, cmap=\"coolwarm\", shading=\"nearest\"\n",
    "    )\n",
    "    cbar = fig.colorbar(ret, ax=ax)\n",
    "    ax.set_xlabel(r\"Space, $x$\")\n",
    "    ax.set_ylabel(r\"Time, $t$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c920d0",
   "metadata": {},
   "source": [
    "## Plot intermediate states during generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34397b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 12\n",
    "fig, axes = plt.subplots(2, 6, sharex=True, sharey=True, figsize=(15, 6))\n",
    "\n",
    "for t, ax in zip(dict_samples.keys(), axes.flatten()):\n",
    "    d = dict_samples[t][0].cpu().numpy()\n",
    "    d = dataloader.dataset.standardize_inversely(d)\n",
    "\n",
    "    ts = np.arange(d.shape[0]) * 0.2  # dt = 0.2\n",
    "    xs = np.linspace(0, 2 * math.pi, 32, endpoint=False)\n",
    "    X, T = np.meshgrid(xs, ts, indexing=\"ij\")\n",
    "\n",
    "    ret = ax.pcolormesh(\n",
    "        X, T, d.transpose(), vmin=-9, vmax=9, cmap=\"coolwarm\", shading=\"nearest\"\n",
    "    )\n",
    "\n",
    "    cbar = fig.colorbar(ret, ax=ax)\n",
    "    ax.set_xlabel(r\"Space, $x$\")\n",
    "    ax.set_ylabel(r\"Time, $t$\")\n",
    "    ax.set_title(f\"Diffusion Step = {t}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
